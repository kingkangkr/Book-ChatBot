import os
import concurrent.futures
from openai import OpenAI

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def chatgpt_generate(prompt):
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"Error generating explanation: {e}"

def generate_explanations(recommendations, book_title, dt):
    explanations = []
    with concurrent.futures.ThreadPoolExecutor() as executor:
        futures = []

        # ğŸ”¹ ì±… ì œëª©ì´ ë°ì´í„°í”„ë ˆì„ì— ì¡´ì¬í•˜ëŠ”ì§€ ë¨¼ì € í™•ì¸
        book_data = dt[dt['Book title'].str.lower() == book_title.lower()]
        if book_data.empty:
            return [f"Error: Book title '{book_title}' not found in dataset."]

        # ğŸ”¹ book_titleì´ ì¡´ì¬í•˜ë©´ ìš”ì•½ì„ ê°€ì ¸ì˜´
        summarized_plot = book_data.iloc[0]['Summarized Plot Summary']

        for title, _ in recommendations:
            recommended_book_data = dt[dt['Book title'] == title]
            if recommended_book_data.empty:
                explanations.append(f"Error: Summary for '{title}' not found.")
                continue

            recommended_plot = recommended_book_data.iloc[0]['Summarized Plot Summary']

            prompt = (
                f"ì±… ì œëª©: {title}\n"
                f"ì¶”ì²œ ì´ìœ : '{book_title}'ê³¼ ìœ ì‚¬í•œ ì¤„ê±°ë¦¬ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. "
                f"ë‘ ì±…ì´ ì–´ë–¤ ì ì—ì„œ ë¹„ìŠ·í•œì§€ ê°„ë‹¨íˆ ì„¤ëª…í•´ ì£¼ì„¸ìš”.\n\n"
                f" **ì£¼ì˜ì‚¬í•­:**\n"
                f"- **ê²°ë§, ë°˜ì „, ì£¼ìš” ì‚¬ê±´ì˜ ê²°ê³¼**ë¥¼ ì ˆëŒ€ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”.\n"
                f"- ì˜¤ì§ ì±…ì˜ **ì„¤ì •, ë“±ì¥ì¸ë¬¼ì˜ íŠ¹ì§•, ë¶„ìœ„ê¸°, ì£¼ì œ**ë§Œ ì„¤ëª…í•˜ì„¸ìš”.\n"
                f"- ë…ìê°€ ì§ì ‘ ì±…ì„ ì½ê³  ê²½í—˜í•  ìˆ˜ ìˆë„ë¡ ê¶ê¸ˆì¦ì„ ìœ ë°œí•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì„œìˆ í•˜ì„¸ìš”.\n\n"
                f"'{book_title}' ìš”ì•½: {summarized_plot}\n"
                f"'{title}' ìš”ì•½: {recommended_plot}\n\n"
            )
            futures.append(executor.submit(chatgpt_generate, prompt))

        for future in concurrent.futures.as_completed(futures):
            explanations.append(future.result())

    return explanations
